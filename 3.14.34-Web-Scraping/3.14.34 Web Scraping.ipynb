{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380b8a16-8be1-47f8-8831-f79d0ea44b64",
   "metadata": {},
   "source": [
    "# 3.14.34 Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428fb8a-87d6-4c3d-8e72-cb6f3292ac2c",
   "metadata": {},
   "source": [
    "### What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d7cd5-e2b0-4012-82b3-95c36be9511f",
   "metadata": {},
   "source": [
    "Web scraping is the art and practice of **retrieving information from a website**. Web scraping can be done manually and, in a sense, it's what we do every time we look up some information on the website or when we copy a table from a Wikipedia page and paste it into a spreadsheet. \n",
    "\n",
    "That said, the most efficient way to scrape a website is through some kind of an automated script and we will explore this practice in Python using a well known scraping library called `BeautifulSoup`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2f37-a94b-4fc7-b703-eb7244cb82ff",
   "metadata": {},
   "source": [
    "### How does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8da2ab-8e4d-48ac-ac55-895c9726dfe5",
   "metadata": {},
   "source": [
    "1. The first step is to locate a website from which you want to extract some information that is embedded in it. It could be an e-Commerce, a news outlet, a weather site or any other website really. \n",
    "2. You should then proceed to inspect and analyze the HTML source code of that web page to find the specific ids and tags that identify the information you're after. \n",
    "3. The central part of a Python scraper is, of course, the script itself. You write an algorithm to instruct your program to use those tags and ids to retrieve the information you're after.\n",
    "4. Finally, you manipulate your results into a data structure of your choice (csv, json, ...) that will allow you to interact with and use your scraped data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1228286-9954-49a8-b139-9202cc76cbd9",
   "metadata": {},
   "source": [
    "<img src=\"img/web-scraping.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a0773-90c9-4a4b-a2a3-c793546637ff",
   "metadata": {},
   "source": [
    "### Is it legal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e469c7-2488-402d-850f-761ef93d35fd",
   "metadata": {},
   "source": [
    "In general terms, web scraping is not illegal. More specifically, according to Wikipedia: *the legality of web scraping varies across the world. In general, web scraping may be against the terms of use of some websites, but the enforceability of these terms is unclear.* \n",
    "\n",
    "It is generally accepted that, if a website makes its data public, then scraping it should be legal. This is reinforced by legal cases such as \"LinkedIn vs hiQ Labs\". You can read more on [Wikipedia](https://en.wikipedia.org/wiki/Web_scraping#Legal_issues) and [online](https://www.parsehub.com/blog/web-scraping-legal/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0dfa1-61b9-4add-827f-06673966a854",
   "metadata": {},
   "source": [
    "### A first simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba22e76d-9c13-420a-a583-2d259f5a5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d00bfc-46e1-47ff-8dba-c3e3910a8873",
   "metadata": {},
   "source": [
    "We will start with a [simple page](https://www.scrapethissite.com/pages/simple/), click on the link and familiarise yourself with its contents; it contains a list of country names from the world and some information for each one of them. \n",
    "\n",
    "Before moving on, inspect the underlying HTML code: right click on an element of the page (for example the name \"Andorra\") and select \"Inspect\". This will open the Inspect Element window in your Chrome browser, which allows you to see the code that generates the page you're looking at. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb753b-6813-469e-9acd-28d376f54b4f",
   "metadata": {},
   "source": [
    "<img src=\"img/inspect-element.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3670df-0749-4a5d-83a2-4d1f7d055fff",
   "metadata": {},
   "source": [
    "In Python, let's start by sending an HTTP GET request to retrieve the HTML content of a desired web page and print to screen the first 1000 characters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bffa0bf4-cdd6-4ac6-95a6-70a087dc22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=\"en\">\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>Countries of the World: A Simple Example | Scrape This Site | A public sandbox for learning web scraping</title>\n",
      "    <link rel=\"icon\" type=\"image/png\" href=\"/static/images/scraper-icon.png\" />\n",
      "\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <meta name=\"description\" content=\"A single page that lists information about all the countries in the world. Good for those just get started with web scraping.\">\n",
      "\n",
      "    <link href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha256-MfvZlkHCEqatNoGiOXveE8FIwMzZg4W85qfrfIFBfYc= sha512-dTfge/zgoMYpP7QbHy4gWMEGsbsdZeCXz7irItjcC3sPUFtf0kuFbDz/ixG7ArTxmDjLXDmezHubeNikyKGVyQ==\" crossorigin=\"anonymous\">\n",
      "    <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>\n",
      "    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/css/styles.css\">\n",
      "\n",
      "    \n",
      "<meta name=\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.scrapethissite.com/pages/simple/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "print(page.text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e02dd-606a-4d0d-84cc-1eb0ef0670a8",
   "metadata": {},
   "source": [
    "Then wew create a Beautiful Soup object named `soup` that takes `page.content` as an input (this is the HTML content we just printed to screen).\n",
    "\n",
    "*Note: it is better to pass page.content instead of page.text to avoid issues with character encoding.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2289cd-efe2-4715-90e4-a5661b77413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33aafe-6bae-46aa-850a-31551bd87e25",
   "metadata": {},
   "source": [
    "If you go back to the **Inspect Element** window, you'll notice that if you hover over an element in the windown on the right, it will highlight on the webpage to the left. We want to retrieve all the country names in the list and the `<div id=\"page\">` element contains all of the results that we're after, so we apply the `.find()` method to the `soup` object in order to find that element via its `id=\"page\"` parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4888f3-367a-4386-b94a-0bd1b2e84591",
   "metadata": {},
   "source": [
    "<img src=\"img/div id=page.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64de315c-3972-496d-9edf-a32de9b1a000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = soup.find(id=\"page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4051077-353c-4966-ba7a-eaffede28840",
   "metadata": {},
   "source": [
    "As we were saying, inside the `results` object there are all the country names we're interested in, but we still need to identify them and to do that we go back to the Inspect Element window and notice that each country block has its name and all related information stored inside a `div` element with `class=\"col-md-4 country\"`. Therefore, we apply the `.find_all()` method to the `results` object in order to get the information about each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97adaf4f-245a-41c7-88b0-09b6d7544785",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = results.find_all(\"div\", class_=\"col-md-4 country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085d896d-9aee-4f9e-a1f8-e8de181779c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"col-md-4 country\">\n",
       "<h3 class=\"country-name\">\n",
       "<i class=\"flag-icon flag-icon-ad\"></i>\n",
       "                            Andorra\n",
       "                        </h3>\n",
       "<div class=\"country-info\">\n",
       "<strong>Capital:</strong> <span class=\"country-capital\">Andorra la Vella</span><br/>\n",
       "<strong>Population:</strong> <span class=\"country-population\">84000</span><br/>\n",
       "<strong>Area (km<sup>2</sup>):</strong> <span class=\"country-area\">468.0</span><br/>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de32cd-5cb7-453f-9989-f2783c0b714b",
   "metadata": {},
   "source": [
    "Now, if you look closely to the above output, you'll notice that each country name is enclosed in a `h3` tag with `class=\"country-name\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6147906-d584-4aa9-91a6-a9476ebee486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c11a16f-a852-4c3a-b70c-b79f578106c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013dc41a-ee68-42dc-bfea-4fa18aec5203",
   "metadata": {},
   "source": [
    "The output object `countries` is an iterable object of class `bs4.element.ResultSet` containing 250 elements, so we can use a for loop to print each element in the `h3` tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72939876-eb37-433a-9984-1916c37173b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 class=\"country-name\">\n",
      "<i class=\"flag-icon flag-icon-ad\"></i>\n",
      "                            Andorra\n",
      "                        </h3>\n",
      "<h3 class=\"country-name\">\n",
      "<i class=\"flag-icon flag-icon-ae\"></i>\n",
      "                            United Arab Emirates\n",
      "                        </h3>\n",
      "<h3 class=\"country-name\">\n",
      "<i class=\"flag-icon flag-icon-af\"></i>\n",
      "                            Afghanistan\n",
      "                        </h3>\n"
     ]
    }
   ],
   "source": [
    "for c in countries[0:3]: \n",
    "    print(c.find(\"h3\", class_=\"country-name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f91b2-632d-48f2-97fd-2d4ddc49d058",
   "metadata": {},
   "source": [
    "As you can see, this prints everything, including the tag itself; in order **to include just the text**, we can add the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e21bba-a75e-410b-b2c9-ea61d06ade14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                            Andorra\n",
      "                        \n",
      "\n",
      "\n",
      "                            United Arab Emirates\n",
      "                        \n",
      "\n",
      "\n",
      "                            Afghanistan\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "for c in countries[0:3]: \n",
    "    print(c.find(\"h3\", class_=\"country-name\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b51b74b-5bf3-4020-a77f-be67df24f126",
   "metadata": {},
   "source": [
    "Now, instead of printing the output to screen, it's better to append each new element to a list in order to store those information for a later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1137bb7e-fd31-4a6c-9c65-d36fa1d9da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = []\n",
    "for c in countries: \n",
    "    listy.append(c.find(\"h3\", class_=\"country-name\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4248f7-f943-487c-a85f-9dacd6533148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n                            Andorra\\n                        ',\n",
       " '\\n\\n                            United Arab Emirates\\n                        ',\n",
       " '\\n\\n                            Afghanistan\\n                        ',\n",
       " '\\n\\n                            Antigua and Barbuda\\n                        ',\n",
       " '\\n\\n                            Anguilla\\n                        ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listy[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe114d-47c3-4ae2-9450-b4e11d1b4b98",
   "metadata": {},
   "source": [
    "Since there are some \"spaces\" and \"return\" characters in the strings, we use the `.strip()` method to remove those from the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd00e4f-ec66-40a6-8f2e-a356b127eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for c in countries: \n",
    "    names.append(c.find(\"h3\", class_=\"country-name\").text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96c61fb7-8c4d-4b5d-be44-e1994de68efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andorra',\n",
       " 'United Arab Emirates',\n",
       " 'Afghanistan',\n",
       " 'Antigua and Barbuda',\n",
       " 'Anguilla']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96698a58-4f0d-439e-a5bc-fae95174577b",
   "metadata": {},
   "source": [
    "That's it, we successfully created a list including all the country names from our initial web page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594768cd-dce3-48df-b4a4-047760e2beae",
   "metadata": {},
   "source": [
    "### A slightly more difficult example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14639292-a2ac-445d-9188-77a46064ff67",
   "metadata": {},
   "source": [
    "At [this link](https://www.imdb.com/chart/top/?ref_=nv_mv_250) you will find a list of the top 250 movies ranked by users from the **IMDB website**. We want to retrieve all of the 250 titles in the ranking and save them in a Python list. \n",
    "\n",
    "We begin by sending an HTTP GET request to retrieve the HTML page and save its contents to a BeautifulSoup object. \n",
    "\n",
    "*Notice the `headers={'Accept-Language': \"lang=en-US\"}` additional parameter, which ensures that the contents are always retrieved in english, no matter what the client language is.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c08b9-fd9c-416b-a7bf-c707d8882af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top/?ref_=nv_mv_250'\n",
    "page = requests.get(url, headers={'Accept-Language': \"lang=en-US\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee4ea5-c81c-4c87-89e2-ca851dfacae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4aa728-bfa0-44ce-a083-f960369f04ad",
   "metadata": {},
   "source": [
    "Using the Element Inspector tool, we can see that each movie title belongs to the `td` tag and is identified by the `class=\"titleColumn\"` parameter. Using the `.find_all()` method, we can find all those occurrences and we save them to an object called `movies`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6042e-aed4-476c-83bd-efdc40338969",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = soup.find_all('td', class_='titleColumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011d559-a0f9-4843-89e2-7ed9bb00c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5d843-b301-419b-892a-1f5c8f30fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6dec3-f67a-46e1-b4e6-9c5844d88109",
   "metadata": {},
   "source": [
    "The `movies` object is a BeautifulSoup `ResultSet` object, which is an iterable and contains all the movie titles we're interested in. We proceed extracting the movie title from each element of the `movies` object by looping through its elements, finding the `a` tag and extracting its text content.\n",
    "\n",
    "*Note: in HTML, an `a` tag defines a hyperlink.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d23ff3-a794-4c68-8d73-e8660f283f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names = []\n",
    "for m in movies: \n",
    "    movie_names.append(m.find('a').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9f242-03c8-4b90-91cf-21655baa92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16519a4f-b42a-49aa-ab07-a9f666a042ff",
   "metadata": {},
   "source": [
    "You may have noticed that the `a` tag (which defines a hyperlink), has an attribute called `title`; this is the title of the link (what is shown if you hover over the link), which includes the names of the director as well as the main actors in the movie. \n",
    "\n",
    "To access this information, we'll use `.attrs.get('title')`: \n",
    "\n",
    "- the `.attrs` attribute allows us to access the attributes in the hyperlink tag, \n",
    "- while the `.get()` method enables us to retrieve the contents of a specific attribute, in this case the `'title'` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51ed7b-856e-425c-9229-22c4cec2aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_cast = []\n",
    "for m in movies: \n",
    "    movie_cast.append(m.find('a').attrs.get('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab187c6-b445-491e-9e7d-b2ed6dd8ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_cast[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e0155-7c79-42e0-aa9c-f74f3fe6f6b6",
   "metadata": {},
   "source": [
    "Finally, let's combine together the two lists `movie_names` and `movie_cast` into a single DataFrame named `df_movies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5dbebf-5ffb-4d20-93ed-496d24031958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.DataFrame(\n",
    "    {'name': movie_names,\n",
    "     'cast': movie_cast\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134207a-f0c9-4697-a940-992bb3453f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
